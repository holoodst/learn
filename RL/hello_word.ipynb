{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "import numpy as np\n",
    "tl.logging.set_verbosity(tl.logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Load or Download MNIST > data/mnist\n",
      "[TL] data/mnist/train-images-idx3-ubyte.gz\n",
      "[TL] data/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train,X_val,y_val,X_test,y_test=tl.files.load_mnist_dataset(shape=(-1,784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##讲数据分为训练集合（training set），验证集(validcation set)和测试集(testing set)把每一个手写的数字用一行向量784个进行表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784) (50000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape)##代表有50000个图片作为训练集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_val.shape,y_val.shape)##1000作为验证集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape,y_test.shape)##1000作为测试集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 8 4 8]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##定义一个网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Input  _inputlayer_1: [None, 784]\n",
      "[TL] Dropout dropout_1: keep: 0.800000 \n",
      "[TL] Dense  dense_1: 800 relu\n",
      "[TL] Dropout dropout_2: keep: 0.500000 \n",
      "[TL] Dense  dense_2: 800 relu\n",
      "[TL] Dropout dropout_3: keep: 0.500000 \n",
      "[TL] Dense  dense_3: 10 No Activation\n"
     ]
    }
   ],
   "source": [
    "ni=tl.layers.Input([None,784])##其实代表了batch 一批几个这个none 784代表一个数字 将一个数字拉成1行784列\n",
    "nn=tl.layers.Dropout(keep=0.8)(ni)\n",
    "nn=tl.layers.Dense(n_units=800,act=tf.nn.relu)(nn)\n",
    "nn=tl.layers.Dropout(keep=0.5)(nn)\n",
    "nn=tl.layers.Dense(n_units=800,act=tf.nn.relu)(nn)\n",
    "nn=tl.layers.Dropout(keep=0.5)(nn)\n",
    "nn=tl.layers.Dense(n_units=10,act=None)(nn)\n",
    "network=tl.models.Model(inputs=ni,outputs=nn,name=\"mlp_simp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##定义准确率函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(_logits,y_batch):\n",
    "    return tf.reduce_mean(\n",
    "    tf.cast(tf.equal(tf.argmax(_logits,1),tf.convert_to_tensor(y_batch,tf.int64)),tf.float32,name='accuracy')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##tf.euqal \n",
    "##x = tf.constant([2, 4])\n",
    "##y = tf.constant(2)\n",
    "##tf.math.equal(x, y) ==> array([True, False])\n",
    "##tf.equal(tf.argmax(_logits,1),tf.convert_to_tensor(y_batch,tf.int64)) 是预估值和标签值相等判断后输出的列表\n",
    "##tf.reduce_mean求均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp_simp(\n",
      "  (_inputlayer_1): Input(shape=[None, 784], name='_inputlayer_1')\n",
      "  (dropout_1): Dropout(keep=0.8, name='dropout_1')\n",
      "  (dense_1): Dense(n_units=800, relu, in_channels='784', name='dense_1')\n",
      "  (dropout_2): Dropout(keep=0.5, name='dropout_2')\n",
      "  (dense_2): Dense(n_units=800, relu, in_channels='800', name='dense_2')\n",
      "  (dropout_3): Dropout(keep=0.5, name='dropout_3')\n",
      "  (dense_3): Dense(n_units=10, No Activation, in_channels='800', name='dense_3')\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##训练模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Setting up tensorboard ...\n",
      "[TL] [!] ./tb_loog exists ...\n",
      "[TL] Start training the network ...\n",
      "[TL] Epoch 1 of 20 took 10.085436s\n",
      "[TL]    train loss: 0.410896\n",
      "[TL]    train acc: 0.883033\n",
      "[TL] Epoch 5 of 20 took 9.307992s\n",
      "[TL]    train loss: 0.191777\n",
      "[TL]    train acc: 0.942488\n",
      "[TL] Epoch 10 of 20 took 7.562018s\n",
      "[TL]    train loss: 0.123512\n",
      "[TL]    train acc: 0.962400\n",
      "[TL] Epoch 15 of 20 took 7.625322s\n",
      "[TL]    train loss: 0.088859\n",
      "[TL]    train acc: 0.972857\n",
      "[TL] Epoch 20 of 20 took 7.713785s\n",
      "[TL]    train loss: 0.068076\n",
      "[TL]    train acc: 0.979607\n",
      "[TL] Total training time: 126.768179s\n"
     ]
    }
   ],
   "source": [
    "tl.utils.fit(\n",
    "    network, train_op=tf.optimizers.Adam(learning_rate=0.0001), cost=tl.cost.cross_entropy, X_train=X_train,\n",
    "    y_train=y_train, acc=acc, batch_size=256, n_epoch=20, X_val=X_val, y_val=y_val, eval_train=True,\n",
    "    tensorboard_dir='./tb_loog'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Start testing the network ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=51735, shape=(), dtype=float32, numpy=0.9743>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.utils.test(network, acc, X_test, y_test, batch_size=None, cost=tl.cost.cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.utils.test?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-2.271208   -2.6272442   2.2785277  ... 11.591954   -3.7504613\n",
      "   0.34867537]\n",
      " [-1.614523    2.086506   10.253306   ... -5.161183    0.20881243\n",
      "  -8.756842  ]\n",
      " [-4.453318    8.496254   -0.20584133 ...  0.87646633 -0.85555\n",
      "  -3.5992785 ]\n",
      " ...\n",
      " [-7.637353   -3.6960683  -4.9947667  ... -0.18907967  0.19720453\n",
      "   3.927492  ]\n",
      " [-0.7638174  -2.0758698  -6.183501   ... -4.523805    3.2531538\n",
      "  -3.380673  ]\n",
      " [ 0.2428626  -3.8809628   0.7159096  ... -7.7537045  -3.403752\n",
      "  -5.6272707 ]], shape=(10000, 10), dtype=float32)\n",
      "[7 2 1 ... 4 5 6]\n",
      "[TL] confusion matrix: \n",
      "[[ 971    0    0    0    0    1    4    1    2    1]\n",
      " [   0 1126    2    1    0    1    3    0    2    0]\n",
      " [   7    0 1002    3    1    0    3    7    9    0]\n",
      " [   1    0    4  984    0    8    0    5    7    1]\n",
      " [   2    0    2    0  951    0    6    3    2   16]\n",
      " [   4    0    0    7    1  870    6    0    3    1]\n",
      " [   5    3    0    1    5    3  939    0    2    0]\n",
      " [   2    8   11    2    1    1    0  993    0   10]\n",
      " [   4    0    2    7    3    4    5    4  941    4]\n",
      " [   4    6    2   10    8    2    1    4    6  966]]\n",
      "[TL] f1-score        : [0.98080808 0.98858648 0.97423432 0.97185185 0.97438525 0.97643098\n",
      " 0.97558442 0.97114914 0.9661191  0.96215139]\n",
      "[TL] f1-score(macro) : 0.974130\n",
      "[TL] accuracy-score  : 0.974300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 971,    0,    0,    0,    0,    1,    4,    1,    2,    1],\n",
       "        [   0, 1126,    2,    1,    0,    1,    3,    0,    2,    0],\n",
       "        [   7,    0, 1002,    3,    1,    0,    3,    7,    9,    0],\n",
       "        [   1,    0,    4,  984,    0,    8,    0,    5,    7,    1],\n",
       "        [   2,    0,    2,    0,  951,    0,    6,    3,    2,   16],\n",
       "        [   4,    0,    0,    7,    1,  870,    6,    0,    3,    1],\n",
       "        [   5,    3,    0,    1,    5,    3,  939,    0,    2,    0],\n",
       "        [   2,    8,   11,    2,    1,    1,    0,  993,    0,   10],\n",
       "        [   4,    0,    2,    7,    3,    4,    5,    4,  941,    4],\n",
       "        [   4,    6,    2,   10,    8,    2,    1,    4,    6,  966]]),\n",
       " array([0.98080808, 0.98858648, 0.97423432, 0.97185185, 0.97438525,\n",
       "        0.97643098, 0.97558442, 0.97114914, 0.9661191 , 0.96215139]),\n",
       " 0.9743,\n",
       " 0.9741301006958564)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_logits = tl.utils.predict(network, X_test)\n",
    "print(_logits)\n",
    "y_pred = np.argmax(_logits, 1)\n",
    "print(y_pred)\n",
    "tl.utils.evaluation(y_test, y_pred, n_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10000, 10])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=51769, shape=(10,), dtype=float32, numpy=\n",
       "array([-1.614523  ,  2.086506  , 10.253306  ,  2.7536051 , -7.9567223 ,\n",
       "       -1.6947469 , -2.5419915 , -5.161183  ,  0.20881243, -8.756842  ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_logits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(_logits, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] confusion matrix: \n",
      "[[ 971    0    0    0    0    1    4    1    2    1]\n",
      " [   0 1126    2    1    0    1    3    0    2    0]\n",
      " [   7    0 1002    3    1    0    3    7    9    0]\n",
      " [   1    0    4  984    0    8    0    5    7    1]\n",
      " [   2    0    2    0  951    0    6    3    2   16]\n",
      " [   4    0    0    7    1  870    6    0    3    1]\n",
      " [   5    3    0    1    5    3  939    0    2    0]\n",
      " [   2    8   11    2    1    1    0  993    0   10]\n",
      " [   4    0    2    7    3    4    5    4  941    4]\n",
      " [   4    6    2   10    8    2    1    4    6  966]]\n",
      "[TL] f1-score        : [0.98080808 0.98858648 0.97423432 0.97185185 0.97438525 0.97643098\n",
      " 0.97558442 0.97114914 0.9661191  0.96215139]\n",
      "[TL] f1-score(macro) : 0.974130\n",
      "[TL] accuracy-score  : 0.974300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 971,    0,    0,    0,    0,    1,    4,    1,    2,    1],\n",
       "        [   0, 1126,    2,    1,    0,    1,    3,    0,    2,    0],\n",
       "        [   7,    0, 1002,    3,    1,    0,    3,    7,    9,    0],\n",
       "        [   1,    0,    4,  984,    0,    8,    0,    5,    7,    1],\n",
       "        [   2,    0,    2,    0,  951,    0,    6,    3,    2,   16],\n",
       "        [   4,    0,    0,    7,    1,  870,    6,    0,    3,    1],\n",
       "        [   5,    3,    0,    1,    5,    3,  939,    0,    2,    0],\n",
       "        [   2,    8,   11,    2,    1,    1,    0,  993,    0,   10],\n",
       "        [   4,    0,    2,    7,    3,    4,    5,    4,  941,    4],\n",
       "        [   4,    6,    2,   10,    8,    2,    1,    4,    6,  966]]),\n",
       " array([0.98080808, 0.98858648, 0.97423432, 0.97185185, 0.97438525,\n",
       "        0.97643098, 0.97558442, 0.97114914, 0.9661191 , 0.96215139]),\n",
       " 0.9743,\n",
       " 0.9741301006958564)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.utils.evaluation(y_test, y_pred, n_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] [*] Saving TL weights into helloword.h5\n",
      "[TL] [*] Saved\n"
     ]
    }
   ],
   "source": [
    "network.save_weights('helloword.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
